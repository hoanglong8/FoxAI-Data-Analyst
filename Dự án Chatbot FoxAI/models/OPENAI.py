import os
import base64
import fitz  # PyMuPDF for extracting text from PDFs
import openai  # OpenAI SDK

def configure_openai(openai_api_key):
    """Khá»Ÿi táº¡o OpenAI client vá»›i API key."""
    if not openai_api_key:
        raise ValueError("âš ï¸ OPENAI_API_KEY chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p trong biáº¿n mÃ´i trÆ°á»ng!")
    
    client = openai.OpenAI(api_key=openai_api_key)
    return client

# âœ… HÃ m xá»­ lÃ½ tin nháº¯n vÄƒn báº£n
def get_openai_response(client, user_id, user_message, user_conversations):
    """
    Nháº­n tin nháº¯n vÄƒn báº£n tá»« ngÆ°á»i dÃ¹ng, gá»­i tá»›i OpenAI, 
    vÃ  tráº£ vá» pháº£n há»“i dÆ°á»›i dáº¡ng chuá»—i.
    """
    if user_id not in user_conversations:
        user_conversations[user_id] = []

    # ThÃªm tin nháº¯n ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­
    user_conversations[user_id].append({"role": "user", "content": user_message})

    # Gá»i API OpenAI
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=user_conversations[user_id],
        temperature=0.5,
        max_tokens=1500,
        top_p=0.9
    )

    # Láº¥y ná»™i dung pháº£n há»“i
    reply = response.choices[0].message.content
    # LÆ°u vÃ o lá»‹ch sá»­ há»™i thoáº¡i
    user_conversations[user_id].append({"role": "assistant", "content": reply})

    return reply

# âœ… Há»— trá»£ Ä‘á»c áº£nh
def encode_image(image_path):
    """Chuyá»ƒn Ä‘á»•i áº£nh sang base64 Ä‘á»ƒ gá»­i Ä‘áº¿n OpenAI."""
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"âŒ áº¢nh khÃ´ng tá»“n táº¡i: {image_path}")
    
    with open(image_path, "rb") as f:
        image_binary = f.read()
    base64_image = base64.b64encode(image_binary).decode("utf-8")
    return f"data:image/png;base64,{base64_image}"

def get_openai_image_response(client, user_id, image_path, user_conversations):
    """Gá»­i áº£nh Ä‘áº¿n OpenAI GPT-4o Ä‘á»ƒ phÃ¢n tÃ­ch."""
    if user_id not in user_conversations:
        user_conversations[user_id] = []
    
    data_url = encode_image(image_path)
    
    system_message = {
        "role": "system",
        "content": "Báº¡n lÃ  má»™t AI cÃ³ kháº£ nÄƒng phÃ¢n tÃ­ch hÃ¬nh áº£nh vá»›i GPT-4o."
    }
    
    user_message = {
        "role": "user",
        "content": [
            {"type": "text", "text": "Analyze this image."},
            {"type": "image_url", "image_url": {"url": data_url}}
        ]
    }
    
    user_conversations[user_id].append(system_message)
    user_conversations[user_id].append(user_message)
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=user_conversations[user_id],
        temperature=0.5,
        max_tokens=1500,
        top_p=0.9
    )
    
    reply = response.choices[0].message.content
    user_conversations[user_id].append({"role": "assistant", "content": reply})
    return reply

# âœ… Há»— trá»£ Ä‘á»c PDF
def extract_text_from_pdf(pdf_path):
    """TrÃ­ch xuáº¥t vÄƒn báº£n tá»« file PDF."""
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"âŒ Lá»—i: File PDF khÃ´ng tá»“n táº¡i! Kiá»ƒm tra Ä‘Æ°á»ng dáº«n: {pdf_path}")

    text = ""
    try:
        with fitz.open(pdf_path) as doc:
            for page in doc:
                text += page.get_text("text") + "\n"
    except Exception as e:
        raise ValueError(f"ğŸš¨ Lá»—i khi Ä‘á»c PDF: {str(e)}")
    
    return text[:5000]  # Giá»›i háº¡n 5000 kÃ½ tá»± Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i token

def get_openai_pdf_response(client, user_id, pdf_path, user_conversations):
    """Äá»c ná»™i dung PDF, gá»­i lÃªn GPT Ä‘á»ƒ tÃ³m táº¯t hoáº·c phÃ¢n tÃ­ch."""
    pdf_text = extract_text_from_pdf(pdf_path)

    if user_id not in user_conversations:
        user_conversations[user_id] = []

    user_message = {
        "role": "user",
        "content": f"ÄÃ¢y lÃ  ná»™i dung cá»§a file PDF:\n\n{pdf_text}\n\nVui lÃ²ng tÃ³m táº¯t tÃ i liá»‡u nÃ y."
    }
    
    user_conversations[user_id].append(user_message)

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=user_conversations[user_id],
        temperature=0.7,
        max_tokens=900,
        top_p=0.9
    )

    reply = response.choices[0].message.content
    user_conversations[user_id].append({"role": "assistant", "content": reply})
    return reply

if __name__ == "__main__":
    openai_api_key = os.getenv("OPENAI_API_KEY")
    client = configure_openai(openai_api_key)
    user_conversations = {}
    user_id = "user_123"

    # ğŸ–¼ï¸ Test Ä‘á»c áº£nh
    image_path = "C:/Users/Admin/Pictures/Camera Roll/sample_image.jpg"
    
    try:
        image_response = get_openai_image_response(client, user_id, image_path, user_conversations)
        print("Assistant's Reply (Image Analysis):\n", image_response)
    except Exception as e:
        print("ğŸš¨ Lá»—i xá»­ lÃ½ áº£nh:", e)

    # ğŸ“„ Test Ä‘á»c PDF
    pdf_path = "C:/Users/ADMIN/Downloads"
    
    try:
        pdf_response = get_openai_pdf_response(client, user_id, pdf_path, user_conversations)
        print("Assistant's Reply (PDF Analysis):\n", pdf_response)
    except Exception as e:
        print("ğŸš¨ Lá»—i xá»­ lÃ½ PDF:", e)
